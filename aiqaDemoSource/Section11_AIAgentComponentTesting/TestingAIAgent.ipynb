{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test AI Agent ðŸ¤– Tool Calling with DeepEval ðŸ§ª\n",
    "\n",
    "Testing AI Agent involves testing of the Tools being invoked by an AI Agent. Here, AI Agent will invoke the necessary tools based on the given input and respond with the help of the tools being bounded with the AI Agent\n",
    "\n",
    "\n",
    "<img src=\"./img/AIAGent.png\" width=\"800\" height=\"400\" style=\"display: block; margin: auto;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸŽ‰ðŸ¥³ Congratulations! You've successfully logged in! ðŸ™Œ \n",
       "</pre>\n"
      ],
      "text/plain": [
       "ðŸŽ‰ðŸ¥³ Congratulations! You've successfully logged in! ðŸ™Œ \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import deepeval\n",
    "\n",
    "deepeval.login_with_confident_api_key(\"o6wy2TTe0igTiXs6zs6/JnR+wfzws96MGYfsqGOzntA=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ™Œ Congratulations! You're now using a local Ollama model for all evals that \n",
      "require an LLM.\n"
     ]
    }
   ],
   "source": [
    "!deepeval set-ollama deepseek-r1:8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.metrics import ToolCorrectnessMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.test_case import ToolCall\n",
    "from deepeval.tracing import (\n",
    "    observe,\n",
    "    update_current_span\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "@observe(type='llm', model='qwen2.5:latest')\n",
    "def local_llms():\n",
    "    return ChatOllama(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model = \"qwen2.5:latest\",\n",
    "        temperature=0.5,\n",
    "        max_tokens = 250\n",
    "    )\n",
    "\n",
    "llm = local_llms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AI Agent with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "s_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "@tool\n",
    "@observe(type='tool')\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"Add two numbers and return results.\"\n",
    "    result = int(a) + int(b)\n",
    "    return f\"The sum of {a} and {b} is {result}\"\n",
    "\n",
    "@tool\n",
    "@observe(type='tool')\n",
    "def subtract_numbers(a: int, b: int) -> int:\n",
    "    \"Subtract two numbers and return results.\"\n",
    "    result = int(a) - int(b)\n",
    "    return f\"The difference of {a} and {b} is {result}\"\n",
    "\n",
    "@tool\n",
    "@observe(type='tool')\n",
    "def search_tool(query):\n",
    "    \"Tool to search online for the given query and return results\"\n",
    "    return s_tool.run(query)\n",
    "\n",
    "tools = [add_numbers, subtract_numbers, search_tool]\n",
    "\n",
    "\n",
    "@observe(type='agent', available_tools=[\"add_numbers\", \"subtract_numbers\", \"search_tool\"], metrics=[ToolCorrectnessMetric()])\n",
    "def main_ai_agent(query):\n",
    "    agent = initialize_agent(\n",
    "        tools= tools,\n",
    "        llm=llm,\n",
    "        agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True\n",
    "    )\n",
    "    \n",
    "    response = agent.invoke(query)\n",
    "    \n",
    "    update_current_span(\n",
    "        test_case=LLMTestCase(\n",
    "            input=query,\n",
    "            tools_called=[ToolCall(name=\"add_numbers\")],\n",
    "            expected_tools=[ToolCall(name=\"add_numbers\")],\n",
    "            actual_output=response['output']\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_response = main_ai_agent(\"Who is the current president of USA in 2025, just give the name\")\n",
    "# add_response = main_ai_agent(\"What is the sum of 20 and 90\")\n",
    "# sub_response = main_ai_agent(\"What is the subtract of 100 with 50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating AI Agent with DeepEval for Component Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating goldens: |          |  0% (0/1) [Time Taken: 00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"add_numbers\",\n",
      "  \"action_input\": {\n",
      "    \"a\": 20,\n",
      "    \"b\": 90\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe sum of 20 and 90 is 110\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The sum of 20 and 90 is 110\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Ending trace: [BaseSpan(uuid='0ed8fa1e-a183-4144-a82f-cfa044ccb01c', status=<TraceSpanStatus.SUCCESS: 'SUCCESS'>, children=[AgentSpan(uuid='6d6a1b4f-1ab9-4dd0-922a-e89fb4c3fe8e', status=<TraceSpanStatus.SUCCESS: 'SUCCESS'>, children=[ToolSpan(uuid='7d5d037f-6556-4962-94ed-c615e8ec711d', status=<TraceSpanStatus.SUCCESS: 'SUCCESS'>, children=[], trace_uuid='9b058f62-6321-42b5-8760-5e1be474423a', parent_uuid='6d6a1b4f-1ab9-4dd0-922a-e89fb4c3fe8e', start_time=341291.427179, end_time=341291.427200208, name='add_numbers', metadata=None, input={'a': 20, 'b': 90}, output='The sum of 20 and 90 is 110', error=None, llm_test_case=None, metrics=None, attributes=None, description=None)], trace_uuid='9b058f62-6321-42b5-8760-5e1be474423a', parent_uuid='0ed8fa1e-a183-4144-a82f-cfa044ccb01c', start_time=341287.389004791, end_time=341292.473865208, name='main_ai_agent', metadata=None, input={'query': 'What is the sum of 20 and 90'}, output={'input': 'What is the sum of 20 and 90', 'output': 'The sum of 20 and 90 is 110', 'intermediate_steps': [(AgentAction(tool='add_numbers', tool_input={'a': 20, 'b': 90}, log='Action:\\n```\\n{\\n  \"action\": \"add_numbers\",\\n  \"action_input\": {\\n    \"a\": 20,\\n    \"b\": 90\\n  }\\n}\\n```'), 'The sum of 20 and 90 is 110')]}, error=None, llm_test_case=LLMTestCase(input='What is the sum of 20 and 90', actual_output='The sum of 20 and 90 is 110', expected_output=None, context=None, retrieval_context=None, additional_metadata=None, comments=None, tools_called=[ToolCall(\n",
      "    name=\"add_numbers\"\n",
      ")], expected_tools=[ToolCall(\n",
      "    name=\"add_numbers\"\n",
      ")], token_cost=None, completion_time=None, name=None), metrics=[<deepeval.metrics.tool_correctness.tool_correctness.ToolCorrectnessMetric object at 0x128e9cc80>], available_tools=['add_numbers', 'subtract_numbers', 'search_tool'], agent_handoffs=[], attributes=None)], trace_uuid='9b058f62-6321-42b5-8760-5e1be474423a', parent_uuid=None, start_time=341287.38889975, end_time=341292.473882083, name='Test Wrapper', metadata=None, input={}, output=None, error=None, llm_test_case=None, metrics=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Evaluating goldens: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|100% (1/1) [Time Taken: 00:05,  5.09s/it]\n",
      "     âš¡ Invoking traceable callback: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|100% (1/1) [Time Taken: 00:05,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What is the sum of 20 and 90\n",
      "  - actual output: None\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Tests finished ðŸŽ‰! View results on \n",
       "<a href=\"https://app.confident-ai.com/project/cmb8sq46q07rf1tfo1k6r68x4/evaluation/test-runs/cmbhe6qre09n9ei18oltm3zw2/compare-test-results\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://app.confident-ai.com/project/cmb8sq46q07rf1tfo1k6r68x4/evaluation/test-runs/cmbhe6qre09n9ei18oltm3zw2/compa</span></a>\n",
       "<a href=\"https://app.confident-ai.com/project/cmb8sq46q07rf1tfo1k6r68x4/evaluation/test-runs/cmbhe6qre09n9ei18oltm3zw2/compare-test-results\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">re-test-results</span></a><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;5;245;141mâœ“\u001b[0m Tests finished ðŸŽ‰! View results on \n",
       "\u001b]8;id=583955;https://app.confident-ai.com/project/cmb8sq46q07rf1tfo1k6r68x4/evaluation/test-runs/cmbhe6qre09n9ei18oltm3zw2/compare-test-results\u001b\\\u001b[4;94mhttps://app.confident-ai.com/project/cmb8sq46q07rf1tfo1k6r68x4/evaluation/test-runs/cmbhe6qre09n9ei18oltm3zw2/compa\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b]8;id=583955;https://app.confident-ai.com/project/cmb8sq46q07rf1tfo1k6r68x4/evaluation/test-runs/cmbhe6qre09n9ei18oltm3zw2/compare-test-results\u001b\\\u001b[4;94mre-test-results\u001b[0m\u001b]8;;\u001b\\\u001b[4;94m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_1', success=True, metrics_data=[], conversational=False, multimodal=False, input='What is the sum of 20 and 90', actual_output=None, expected_output=None, context=None, retrieval_context=None, additional_metadata=None)], confident_link='https://app.confident-ai.com/project/cmb8sq46q07rf1tfo1k6r68x4/evaluation/test-runs/cmbhe6qre09n9ei18oltm3zw2/compare-test-results')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval.dataset import Golden\n",
    "from deepeval import evaluate\n",
    "\n",
    "goldens = Golden(input=\"What is the sum of 20 and 90\")\n",
    "evaluate(goldens=[goldens], observed_callback=main_ai_agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
